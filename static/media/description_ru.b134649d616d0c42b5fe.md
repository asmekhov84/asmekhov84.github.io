В одном из проектов, связанных с локализацией объектов по облакам точек, возникла необходимость проведения виртуальных экспериментов, так как была нехватка реальных данных. Я получил задачу создать виртуальную камеру глубины, которая позволяла бы имитировать реальный датчик и получать облака точек с разных ракурсов, имея CAD модели всех объектов сцены.

По принципу работы камера глубины похожа на обычную камеру, но помимо яркости для каждого пикселя она выдаёт трёхмерные координаты соответствующей точки. Зная положение камеры во время каждого снимка, можно объединить несколько облаков точек, снятых с разных ракурсов, и получить детальное облако точек сцены, значительно превышающей по размеру поле зрения камеры.

Разработанный мной метод использует алгоритм ray casting. Он моделирует распространение световых лучей от каждого пикселя матрицы камеры по направлению к сцене и позволяет определить координаты точек пересечения лучей с объектами сцены. Этот метод использует структуру данных AABB tree (axis aligned bounding box tree) из библиотеки LibIGL для поиска точек пересечения лучей с объектами. Для каждого луча в качестве результата берётся ближайшая к камере точка пересечения.

Такой подход позволяет достаточно точно имитировать реальную камеру глубины. Есть возможность менять такие параметры, как разрешение матрицы, горизонтальный и вертикальный углы поля зрения (FOV), а также матрицу трансформации, определяющую положение камеры на сцене. Этот алгоритм позволяет легко генерировать синтетические данные, когда у нас нет реальной камеры или объекта сканирования, но мы знаем параметры камеры и у нас есть трёхмерная модель объекта. Кроме того, к полученному облаку точек можно добавить случайный шум, чтобы сделать данные более похожими на реальные.

На рисунках ниже можно видеть облака точек, полученные виртуальной камерой глубины. В качестве объекта сканирования использовалась модель головы манекена.
